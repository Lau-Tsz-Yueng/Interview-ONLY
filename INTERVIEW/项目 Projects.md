# 1.	嵌入式实时操作系统
# 硬实时方面
主要是FPGA(可编程门阵列)去将ARM处理器替换之前在系统上的Leon3处理器, 相比ARM处理器的Leon3生态太过庞大,繁琐不适用于无人机这种对重量, 空间, 时间, 能源以及成本要求极高的应用场合。
ARM处理速度快, 代码量轻, 无论在开发成本还是实时性都优于Leon3处理器。所以我们使用VHDL设计了一个"系统总线桥梁"让ARM对系统接口进行映射 因为接口不同, 这就是将ARM嵌入系统的过程。于是硬件环境的部署就完成了。 
ARM采用流水线事务处理 三个阶段fetch指令 decode解码准备控制信号 executeALU结果写入寄存器 支持外围设备中断 运用于实时系统

# 软实时方面
主要实现了一个抢占式动态电压调度算法 主要在FreeRTOS平台运行和编译, 属于功率的管理(power management), 目的最小化能源消耗

# FreeRTOS
FreeRTOS是一个迷你操作系统内核的小型嵌入式系统。是一个轻量级的操作系统, 也是微控制器MCU和小型微处理器的标准解决方案。

# FreeRTOS 特点
FreeRTOS 是一个可裁剪的小型 RTOS 系统，其特点包括：

FreeRTOS 的内核支持抢占式，合作式和时间片调度。
提供了一个用于低功耗的 Tickless 模式。
系统的组件在创建时可以选择动态或者静态的 RAM，比如任务、消息队列、信号量、软件定时器等等。
FreeRTOS-MPU 支持 Corex-M 系列中的 MPU 单元，如 STM32F429。
FreeRTOS 系统简单、小巧、易用，通常情况下内核占用 4k-9k 字节的空间。
高可移植性，代码主要 C 语言编写。
高效的软件定时器。
强大的跟踪执行功能。
堆栈溢出检测功能。
任务数量不限。
任务优先级不限。


# 原理
当前没有工作要执行时, 处理器进入睡眠状态, 睡眠状态也是运行状态。此时, 处理器完全禁止, 其他计时器任务, 任务复活等是在脱机状态下运行, 从而节约资源, 充分提高CPU使用率。

无人机实时系统采用的是7态状态模型, 
创建、就绪、运行、等待、挂起就绪、挂起等待、死亡
Running—运行态
当任务处于实际运行状态称之为运行态，即CPU的使用权被这个任务占用。
Ready—就绪态
处于就绪态的任务是指那些能够运行（没有被阻塞和挂起），但是当前没有运行的任务，因为同优先级或更高优先级的任务正在运行。
Blocked—阻塞态
由于等待信号量，消息队列，事件标志组等而处于的状态被称之为阻塞态，另外任务调用延迟函数也会处于阻塞态。
Suspended—挂起态
类似阻塞态，通过调用函数 vTaskSuspend() 对指定任务进行挂起，挂起后这个任务将不被执行，只有调用函数 xTaskResume() 才可以将这个任务从挂起态恢复。

# 可剥夺型内核 (RTOS采用)
RTOS内核负责管理所有任务 内核决定运行哪个任务 合适停止当前任务切换到其他任务 具有多任务管理能力。伪并发 感觉芯片有很多CPU 多任务管理实现CPU资源的最大化利用。可剥夺内核 就是可以剥夺其他任务的CPU使用权 它总是运行就就绪任务中优先级最高的任务。 

优先级反转 优先级继承 (实现资源的同步) -> 饥饿
当一个高优先级任务p等待资源, 导致低优先级任务q被锁住, 高优先级任务会从等待态到挂起等待态, 任务放进外存, 然后进程p按照q的优先级去执行(优先级继承), 等待原本高优先级任务等待事件结束时, 此时再进入挂起就绪态, 当内存没有就绪态进程, 如果挂起就绪态优先级比就绪态进程高, 进程切换为就绪态。

# 实时系统
实时操作系统方面, 特点与计算机操作系统不同当然是实时性, 系统需要能容忍任务一定的超时, 要求任务要在一个确定的时间内响应。并且拥有中断机制, 由系统调用, 立即切换上下文, 节约资源。

因为实时系统是抢占式的调度算法, 并且可以中断当前任务, 从而优先权大的任务抢占当前处理器资源。

实时系统的调度算法分为静态和动态的：
固定优先级调度 FPS
每一个进程是固定的, 静态的优先级队列 并且在运行之前就已经被排序过了的
有单调速率调度

# 动态优先级调度 DPS
进程的运行顺序是依于进程的绝对deadlines
下一个进程的执行是依照最短的deadline去执行的
虽然进程的相对deadline可以被推断, 但是绝对deadline是在运行时被决定的
Earliest Deadline First 最短截止期优先
执行deadline最近的任务

# ARM MMU
ARM CPU上的三个地址：虚拟地址(VA,Virtual Address)、变换后的虚拟地址(MVA,Modified Virtual Address)、物理地址(PA,Physical Address)
   启动MMU后，CPU核对外发出虚拟地址VA，VA被转换为MVA供MMU使用，在这里MVA被转换为PA；最后通过PA读写实际设备 
    MMU的作用就是负责虚拟地址（virtual address）转化成物理地址（physical address）。


为了降低功耗，越来越多的芯片支持动态电压与频率调节DVFS(Dynamic Voltage and Frequency Scaling)。
# DVFS的工作流程：
①	  采集与系统负载有关的信号，计算当前的系统负载 这个过程可以用软件实现，也可以用硬件实现。软件实现一般是在操作系统的核心调用中安放钩子，特别是调度器，根据其调用的频度来判断系统的负载
②	根据系统的当前负载，预测系统在下一时间段需要的性能。
③	将预测的性能转换成需要的频率，从而调整芯片的时钟设置。
④	根据新的频率计算相应的电压。通知电源管理模块调整给CPU的电压。

在基于软件的DVFS实现中，一般通过在操作系统的核心调用中安装钩子的办法来收集系统调用的信息，判断当前的系统负载。其中最重要的是调度器，其他地方包括读/写接口、定时器等。例如，在Linux内核中，一般在以下地方安装钩子。
◇ kernel/sched.c。修改__schedule()，在schedule()前和后插入语句，记录一个任务的执行时间。
◇ fs/read_write.c。修改sys_read()和sys_write()，记录其被某任务调用的次数。
◇ kernel/timer.c。修改sys_nanosleep()和msleep()，记录任务主动休息的时间。
◇ fs/ioctl.c。修改sys_ioctl()，记录其被调用的次数。
◇ kernel/exit.c。修改do_exit()，记录任务主动退出的时间。
◇ include/asm_xxx/system.h, arch/xxx/system.c。修改arch_idle()，计算cpu_idle()线程被调用的时间。

在预测下一时间段的系统负载时，需要利用采集到的前面几个时间段的实际负载值。

# 2.	基于循环神经网络的时序预测（机器学习）
时序数据库
时间序列数据库主要用于指处理带时间标签（按照时间的顺序变化，即时间序列化）的数据。
对于时序大数据的存储和处理往往采用关系型数据库的方式进行处理，但由于关系型数据库天生的劣势导致其无法进行高效的存储和数据的查询。
时序大数据可以高效存储和快速处理海量时序大数据 
采用特殊数据存储方式，极大提高了时间相关数据的处理能力，相对于关系型数据库它的存储空间减半(时间序列表头分离的特性不浪费空间)，查询速度极大的提高

# RNN 
人类针对每个问题的思考，一般不会是完全的从头开始思考。正如当你阅读这篇译文的时候，你会根据已经阅读过的内容来对后面的内容进行理解，你不会把之前的东西都丢掉从头进行思考，你对内容的理解是贯穿的。
传统的神经网络做不到这一点，而这似乎是一个主要的缺点。 例如，假设您想对电影中的每个事件进行分类。我们无法想象传统神经网络如何能够利用前面的场景去干预后面的预测。
循环神经网络是具有循环的网络，允许信息持续存在, 这种链状特征揭示了循环神经网络与序列和列表密切相关。

# LSTM
长短记忆神经网络——通常称作LSTM，是一种特殊的RNN，能够学习长的依赖关系
LSTM的关键是细胞状态
LSTM确实具有删除或添加信息到细胞状态的能力，这个能力是由被称为门(Gate)的结构所赋予的。
门(Gate)是一种可选地让信息通过的方式。 它由一个Sigmoid神经网络层和一个点乘法运算组成。
LSTM 通过刻意的设计来避免长期依赖问题

# LSTM 训练方法
数据归一化以及划分训练测试集 (7:3)。为了最小化训练误差，使用梯度下降法（Gradient descent）如：应用时序性倒传递算法，可用来依据错误修改每次的权重

# 反向传播
反向传播算法，简称BP算法，适合于多层神经元网络的一种学习算法，它建立在梯度下降法的基础上。BP网络的输入输出关系实质上是一种映射关系


# CNN
卷积神经网络一类包含卷积计算且具有深度结构的前馈神经网络 能够按其阶层结构对输入信息进行平移不变分类

# 监督学习（supervised learning）
从给定的训练数据集中学习出一个函数（模型参数），当新的数据到来时，可以根据这个函数预测结果。监督学习的训练集要求包括输入输出，也可以说是特征和目标

# 无监督学习（unsupervised learning）
人们期望从数据中学习潜在的模式或规则，而不以预先定义的真值作为基准。
输入数据没有被标记，也没有确定的结果。样本数据类别未知，需要根据样本间的相似性对样本集进行分类（聚类，clustering）试图使类内差距最小化，类间差距最大化。通俗点将就是实际应用中，不少情况下无法预先知道样本的标签，也就是说没有训练样本对应的类别，因而只能从原先没有样本标签的样本集开始学习分类器设计。

# 半监督学习
策略是首先将数据聚类成组（无监督学习），然后对每个组分别应用有监督的学习算法。第一阶段的无监督学习可以帮助我们缩小学习的范围，第二阶段的有监督学习可以获得更好的精度。

# 分类 VS. 回归
如果机器学习模型的输出是离散值（discrete values），例如布尔值，那么我们将其称为分类模型。如果输出是连续值（continuous values），那么我们将其称为回归模型。

机器学习工作流所涉及的几个阶段形成了一个以数据为中心的循环过程。
机器学习工作流的最终目标是建立机器学习模型。我们从数据中得到模型。因此，模型所能达到的性能上限是由数据决定的。有许多模型可以拟合特定的数据。我们所能做到最好的，就是找到一个可以最接近于数据所设置的上限的模型。我们不能期望一个模型能够从数据的范围之内学到其他东西。
经验法则： 若输入错误数据，则输出亦为错误数据。

# 欠拟合
欠拟合模型是指不能很好地拟合训练数据的模型，即显著偏离真实值的模型。

# 过拟合
过拟合模型是与训练数据拟合较好的模型，即误差很小或没有误差，但不能很好地推广到不可见数据。


